{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interpreted-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code base is from below\n",
    "# https://github.com/keras-team/keras-io/blob/cbda610b5a73b517aa750e1ff14d7c7a70aae91e/examples/vision/ipynb/retinanet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quality-timing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from encode import LabelEncoder\n",
    "from model import *\n",
    "from losses import RetinaNetLoss\n",
    "\n",
    "from feed import train_data_loader, val_data_loader\n",
    "from inference import DecodePredictions\n",
    "from box_utils import visualize_detections\n",
    "from preprocess import resize_and_pad_image, preprocess_data\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "applied-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-gpu==2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "transparent-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list | grep tensorflow\n",
    "# !pip uninstall tensorflow-gpu -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wooden-stack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-01f7ceb4d0f2>:9: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "  except RuntimeError as e:\n",
    "    # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "    print(e)\n",
    "#     tensorflow gpu 2.5.0 version에서 gpu 인식 실패, 2.4.0으로 해야 된다.\n",
    "print(tf.test.is_gpu_available()   )\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "subsequent-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://github.com/srihari-humbarwadi/datasets/releases/download/v0.1.0/data.zip\"\n",
    "# filename = os.path.join(os.getcwd(), \"../data.zip\")\n",
    "# keras.utils.get_file(filename, url)\n",
    "\n",
    "\n",
    "# with zipfile.ZipFile(\"../data.zip\", \"r\") as z_fp:\n",
    "#     z_fp.extractall(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daily-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"retinanet/\"\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "num_classes = 80\n",
    "batch_size = 2\n",
    "\n",
    "learning_rates = [2.5e-06, 0.000625, 0.00125, 0.0025, 0.00025, 2.5e-05]\n",
    "learning_rate_boundaries = [125, 250, 500, 240000, 360000]\n",
    "learning_rate_fn = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=learning_rate_boundaries, values=learning_rates\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "impressed-classification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0.02825263 -0.01187372  0.00151489  0.0174512   0.02267267 -0.07706022\n",
      "  0.02593261  0.00758947  0.01483854  0.00269824 -0.02794643  0.01281348\n",
      " -0.00239688 -0.02064885 -0.00565647 -0.01334927 -0.07256436 -0.04735989\n",
      "  0.02042213  0.06503097 -0.00141359  0.0067685  -0.00452705  0.00789207\n",
      "  0.0037927  -0.02793706 -0.02059007 -0.01074472 -0.03362909 -0.00028938\n",
      " -0.01099383  0.00777401 -0.02380833  0.00196355  0.04691625  0.00554846\n",
      "  0.01841898 -0.01014032 -0.01754054  0.09017435  0.02368956 -0.02602403\n",
      "  0.01441176 -0.01233377 -0.01345379 -0.00706803 -0.02015607 -0.012672\n",
      " -0.0035574   0.00865486  0.07378456  0.0110056   0.03461925  0.01144895\n",
      "  0.001062    0.00103144  0.00486954  0.02316773  0.0355238  -0.00459298\n",
      " -0.00914957 -0.0107004  -0.05279828 -0.00136667], shape=(64,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "resnet50_backbone = get_resnet_backbone()\n",
    "loss_fn = RetinaNetLoss(num_classes)\n",
    "model = RetinaNet(num_classes, resnet50_backbone)\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate=learning_rate_fn, momentum=0.9)\n",
    "model.compile(loss=loss_fn, optimizer=optimizer)\n",
    "print(model.trainable_variables[0][0][0][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "anonymous-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(model_dir, \"weights\" + \"_epoch_{epoch}\"),\n",
    "        monitor=\"loss\",\n",
    "        save_best_only=False,\n",
    "        save_weights_only=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "intimate-colony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>\n",
      "118287\n",
      "5000\n",
      "sample <class 'dict'>\n",
      "dict_keys(['image', 'image/filename', 'image/id', 'objects'])\n",
      "dict_keys(['area', 'bbox', 'id', 'is_crowd', 'label'])\n",
      "sample <class 'dict'>\n",
      "dict_keys(['image', 'image/filename', 'image/id', 'objects'])\n",
      "dict_keys(['area', 'bbox', 'id', 'is_crowd', 'label'])\n"
     ]
    }
   ],
   "source": [
    "#  set `data_dir=None` to load the complete dataset\n",
    "\n",
    "(train_dataset, val_dataset), dataset_info = tfds.load(\n",
    "    \"coco/2017\", split=[\"train\", \"validation\"], with_info=True, data_dir=\"../data\"\n",
    ")\n",
    "print(type(train_dataset))\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "\n",
    "train_loader = train_data_loader(train_dataset, label_encoder, batch_size=1)\n",
    "val_loader = train_data_loader(val_dataset, label_encoder, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a090c951-26ab-4900-952e-edf0094a190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(train_dataset.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7172195-7707-4442-a69b-d75107df7546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(train_loader.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17475e67-2941-4a8c-8b9c-e4f84c612a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autotune = tf.data.experimental.AUTOTUNE\n",
    "# train_dataset = train_dataset.map(preprocess_data, num_parallel_calls=autotune)\n",
    "# #     train_dataset = train_dataset.shuffle(8 * batch_size)\n",
    "# train_dataset = train_dataset.shuffle(100)\n",
    "# train_dataset = train_dataset.padded_batch(\n",
    "#     batch_size=batch_size, padding_values=(0.0, 1e-8, -1), drop_remainder=True\n",
    "# )\n",
    "# train_dataset = train_dataset.map(\n",
    "#     label_encoder.encode_batch, num_parallel_calls=autotune\n",
    "# )\n",
    "# train_dataset = train_dataset.apply(tf.data.experimental.ignore_errors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3699dfef-1c20-4370-8105-9ae32929ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list(train_dataset.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "trying-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image, label in train_loader:\n",
    "#     print(image.shape)\n",
    "#     print(label.shape)\n",
    "# #     print(label)\n",
    "#     outputs = model(image)\n",
    "#     print(outputs.shape)\n",
    "#     loss = loss_fn(label, outputs)\n",
    "#     print(loss)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-bulletin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "361/500 [====================>.........] - ETA: 35s - loss: 1.8330"
     ]
    }
   ],
   "source": [
    "# Uncomment the following lines, when training on full dataset\n",
    "# train_steps_per_epoch = dataset_info.splits[\"train\"].num_examples // batch_size\n",
    "# val_steps_per_epoch = \\\n",
    "#     dataset_info.splits[\"validation\"].num_examples // batch_size\n",
    "# train_steps = 4 * 100000\n",
    "# epochs = train_steps // train_steps_per_epoch\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "# Running 100 training and 50 validation steps,\n",
    "# remove `.take` when training on the full dataset\n",
    "\n",
    "model.fit(\n",
    "#     train_dataset.take(100),\n",
    "    train_loader.take(500),\n",
    "    validation_data=val_loader.take(50),\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks_list,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cognitive-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to `model_dir` when not using the downloaded weights\n",
    "#weights_dir = \"data\"\n",
    "weights_dir = \"retinanet\"\n",
    "\n",
    "latest_checkpoint = tf.train.latest_checkpoint(weights_dir)\n",
    "model.load_weights(latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unlike-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.keras.Input(shape=[None, None, 3], name=\"image\")\n",
    "predictions = model(image, training=False)\n",
    "detections = DecodePredictions(confidence_threshold=0.5)(image, predictions)\n",
    "inference_model = tf.keras.Model(inputs=image, outputs=detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "forced-spectacular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataset donwload complete\n"
     ]
    }
   ],
   "source": [
    "def prepare_image(image):\n",
    "    image, _, ratio = resize_and_pad_image(image, jitter=None)\n",
    "    image = tf.keras.applications.resnet.preprocess_input(image)\n",
    "    return tf.expand_dims(image, axis=0), ratio\n",
    "\n",
    "val_dataset = tfds.load(\"coco/2017\", split=\"validation\", data_dir=\"data\")\n",
    "print('val dataset donwload complete')\n",
    "int2str = dataset_info.features[\"objects\"][\"label\"].int2str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "lined-somalia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_dataset)\n",
    "# list(val_dataset.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "brutal-albert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "(1, 1152, 896, 3)\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "2 root error(s) found.\n  (0) Not found:  No algorithm worked!\n\t [[node model_1/RetinaNet/FeaturePyramid/model/conv1_conv/Conv2D (defined at /home/beomgon/Object_Detection/tf-retina/mobile-retina/notebooks/../model.py:55) ]]\n\t [[model_1/decode_predictions/ExpandDims_2/_42]]\n  (1) Not found:  No algorithm worked!\n\t [[node model_1/RetinaNet/FeaturePyramid/model/conv1_conv/Conv2D (defined at /home/beomgon/Object_Detection/tf-retina/mobile-retina/notebooks/../model.py:55) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_predict_function_9171]\n\nFunction call stack:\npredict_function -> predict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-52251d2644f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mnum_detections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_detections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_detections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-retina/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-retina/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-retina/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/tf-retina/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-retina/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/tf-retina/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-retina/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found:  No algorithm worked!\n\t [[node model_1/RetinaNet/FeaturePyramid/model/conv1_conv/Conv2D (defined at /home/beomgon/Object_Detection/tf-retina/mobile-retina/notebooks/../model.py:55) ]]\n\t [[model_1/decode_predictions/ExpandDims_2/_42]]\n  (1) Not found:  No algorithm worked!\n\t [[node model_1/RetinaNet/FeaturePyramid/model/conv1_conv/Conv2D (defined at /home/beomgon/Object_Detection/tf-retina/mobile-retina/notebooks/../model.py:55) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_predict_function_9171]\n\nFunction call stack:\npredict_function -> predict_function\n"
     ]
    }
   ],
   "source": [
    "for sample in val_dataset.take(5):\n",
    "    print(type(sample))\n",
    "    image = tf.cast(sample[\"image\"], dtype=tf.float32)\n",
    "    input_image, ratio = prepare_image(image)\n",
    "    print(input_image.shape)\n",
    "    detections = inference_model.predict(input_image)\n",
    "    num_detections = detections.valid_detections[0]\n",
    "    print(num_detections)\n",
    "    class_names = [\n",
    "        int2str(int(x)) for x in detections.nmsed_classes[0][:num_detections]\n",
    "    ]\n",
    "    visualize_detections(\n",
    "        image,\n",
    "        detections.nmsed_boxes[0][:num_detections] / ratio,\n",
    "        class_names,\n",
    "        detections.nmsed_scores[0][:num_detections],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-trunk",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-retina",
   "language": "python",
   "name": "tf-retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
